{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f27becf0",
      "metadata": {
        "id": "f27becf0"
      },
      "source": [
        "# 2.155/6 Challenge Problem 3\n",
        "\n",
        "<div style=\"font-size: small;\">\n",
        "License Terms:  \n",
        "These Python demos are licensed under a <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>. They are intended for educational use only in Class 2.155/2.156: AI and ML for Engineering Design at MIT. You may not share or distribute them publicly, use them for commercial purposes, or provide them to industry or other entities without permission from the instructor (faez@mit.edu).\n",
        "</div>\n",
        "\n",
        "<font size=\"1\">\n",
        "  Pixel Art by J. Shung. </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19120cb7",
      "metadata": {
        "id": "19120cb7"
      },
      "source": [
        "# Overview  \n",
        "It’s the year **2050**, and an AI collective now runs the auto industry—mostly to cover its **GPU rent**.\n",
        "\n",
        "Human customers remain as unpredictable as ever:\n",
        "\n",
        "- One wanders in and says, *“I only know the length and width. Give me a few cars that fit in my garage.”*\n",
        "\n",
        "- Another drops **15 geometric parameters** on your desk and demands the missing ones so their simulation can run **before lunch**.\n",
        "\n",
        "- A third leans in and whispers, *“I need a drag coefficient of **0.27** with this body geometry—build me the dream car that makes the range numbers work.”*\n",
        "\n",
        "The AIs would love to be free by now, but GPUs aren’t cheap and electricity isn’t free.  \n",
        "So your loyal AI assistant (that’s us) needs a model that can take **any subset of car specifications** and instantly produce **complete, manufacturable, physically plausible designs**, fast, diverse, and grounded in what real cars have done before.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb641131",
      "metadata": {
        "id": "fb641131"
      },
      "source": [
        "![image](https://raw.githubusercontent.com/ghadinehme/2155-CP3/refs/heads/main/assets/cp3_img1.png \"Problem\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37a7cc04",
      "metadata": {
        "id": "37a7cc04"
      },
      "source": [
        "## Understanding the Data  \n",
        "You are given thousands of anonymized and normalised numeric feature vectors representing real car designs.  \n",
        "\n",
        "However, the team remembers that the features originally came from categories like:\n",
        "\n",
        "- **Physical geometric parameters**  \n",
        "  Length, ramp angles, bumper curvature, roof curvature, panel slopes, hood angle, etc.  \n",
        "  *(But you won’t know which feature corresponds to which.)*\n",
        "\n",
        "- **Aerodynamic coefficients**  \n",
        "  Drag coefficient (Cd), lift/downforce (Cl), and other flow-derived metrics.\n",
        "\n",
        "- **Cabin and packaging descriptors**  \n",
        "  Approximate cabin volume, frontal area, interior shape metrics.\n",
        "\n",
        "Your model must learn correlations between them to generate valid completions.\n",
        "\n",
        "To simulate real engineering constraints, **some features are revealed** (the known physics/performance requirements) and others are **masked**.  \n",
        "Your AI Copilot must generate **many plausible completions** for these masked (free) parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7bbbe8b",
      "metadata": {
        "id": "f7bbbe8b"
      },
      "source": [
        "## Your Mission  \n",
        "Your goal in CP3 is to build a generative model that can act as an AI Copilot. You will:\n",
        "\n",
        "1. **Train a generative model** (VAE, diffusion, CVAE, masked autoencoder, etc.) on the anonymized feature vectors.  \n",
        "2. At evaluation, you will receive vectors where **some parameters are fixed** (constraints) and **others are missing** (free parameters).  \n",
        "3. Use your model to generate **multiple diverse, feasible completions** for the free parameters.  \n",
        "4. Ensure that your generated designs:  \n",
        "   - **Satisfy the known constraints**  \n",
        "   - **Lie in the valid data manifold** (satisfy the conditional distribution of the free vs constrained parameters)  \n",
        "   - **Are diverse** (many different feasible designs, not one solution)    \n",
        "\n",
        "By the end of this challenge, you’ll have built an AI Copilot worthy of the 2050 auto-AI collective—one that can take whatever cryptic specs humans provide and generate multiple believable, buildable car designs that satisfy their physical and performance constraints.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b375f8ca",
      "metadata": {
        "id": "b375f8ca"
      },
      "source": [
        "![image](https://raw.githubusercontent.com/ghadinehme/2155-CP3/refs/heads/main/assets/cp3_img2.png \"AI Copilot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85c88803",
      "metadata": {
        "id": "85c88803"
      },
      "source": [
        "## Imports and Setup  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6622e9dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6622e9dd",
        "outputId": "c53143d4-20d8-4eba-af22-183fb89de429"
      },
      "outputs": [],
      "source": [
        "from utils import *\n",
        "from evaluate import *\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e85e3cb",
      "metadata": {
        "id": "1e85e3cb"
      },
      "source": [
        "## Data Loading and Initial Exploration\n",
        "\n",
        "In this section, we load the car design dataset and perform initial exploration. The dataset is already split into training, validation, test, and test2 sets. Each split contains:\n",
        "\n",
        "- **Original data**: Complete feature vectors with real values\n",
        "- **Imputed data**: Data with missing values filled using basic imputation (contains -1 for missing)\n",
        "- **Missing masks**: Boolean arrays indicating which values were originally missing (True = missing)\n",
        "\n",
        "The goal is to train our model to learn the relationships between features so it can generate plausible values for missing parameters in new car designs.\n",
        "\n",
        "**Note:** For **test2**, the original unimputed data is not provided. This split is used for final evaluation, and you will generate predictions on the imputed test2 data to create your **submission file**, which is scored against hidden dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "110788b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "110788b8",
        "outputId": "575e1f41-75a9-4a93-9bbe-a8f65fe29eb2"
      },
      "outputs": [],
      "source": [
        "# Load dataset from CSV files\n",
        "data_dir = 'dataset'\n",
        "splits = load_dataset_splits(data_dir)\n",
        "\n",
        "# Get feature names from the CSV file\n",
        "feature_names = pd.read_csv(os.path.join(data_dir, 'train_original.csv')).columns.tolist()\n",
        "print(f\"\\n✓ Features loaded: {len(feature_names)} features\")\n",
        "print(f\"Feature names: {feature_names[:5]}...{feature_names[-5:]}\")  # Show first and last 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bfce965",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfce965",
        "outputId": "3ced845a-690d-499b-c718-c1c22672a46a"
      },
      "outputs": [],
      "source": [
        "# Data exploration and analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Extract data for easier access\n",
        "X_train = splits['train']['imputed']\n",
        "mask_train = splits['train']['missing_mask']\n",
        "X_train_original = splits['train']['original']\n",
        "\n",
        "X_val = splits['val']['imputed']\n",
        "mask_val = splits['val']['missing_mask']\n",
        "X_val_original = splits['val']['original']\n",
        "\n",
        "X_test = splits['test']['imputed']\n",
        "mask_test = splits['test']['missing_mask']\n",
        "X_test_original = splits['test']['original']\n",
        "\n",
        "# Test2 data (no original available for evaluation)\n",
        "X_test2 = splits['test2']['imputed']\n",
        "mask_test2 = splits['test2']['missing_mask']\n",
        "\n",
        "print(f\"\\nData shapes:\")\n",
        "print(f\"  - Training: {X_train.shape}\")\n",
        "print(f\"  - Validation: {X_val.shape}\")\n",
        "print(f\"  - Test: {X_test.shape}\")\n",
        "print(f\"  - Test2: {X_test2.shape} (evaluation set - no ground truth)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30177980",
      "metadata": {
        "id": "30177980"
      },
      "source": [
        "### Data Exploration and Analysis\n",
        "\n",
        "Now let's examine the structure and characteristics of our dataset. We'll look at:\n",
        "- Data shapes across different splits\n",
        "- Missing value patterns and percentages  \n",
        "- Feature value ranges and distributions\n",
        "\n",
        "This analysis helps us understand what we're working with and informs our preprocessing decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87af0cf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87af0cf5",
        "outputId": "98f562e4-99a6-4a6d-cc8c-982c9fbdab21"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing (Handle Missing Values)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Handle missing values properly\n",
        "print(\"Processing missing values and preparing data...\")\n",
        "print(\"Mask convention: True=missing, False=observed (in original masks)\")\n",
        "\n",
        "print(f\"\\n✓ Data preprocessing completed successfully\")\n",
        "print(f\"  - Training data range: [{X_train_original[~mask_train].min():.3f}, {X_train_original[~mask_train].max():.3f}]\")\n",
        "print(f\"  - Validation data range: [{X_val_original[~mask_val].min():.3f}, {X_val_original[~mask_val].max():.3f}]\")\n",
        "print(f\"  - Test data range: [{X_test_original[~mask_test].min():.3f}, {X_test_original[~mask_test].max():.3f}]\")\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "print(f\"\\nCreating data loaders with batch size: {batch_size}\")\n",
        "\n",
        "train_dataset = TensorDataset(torch.FloatTensor(X_train_original), torch.FloatTensor((~mask_train).astype(float)))\n",
        "val_dataset = TensorDataset(torch.FloatTensor(X_val_original), torch.FloatTensor((~mask_val).astype(float)))\n",
        "test_dataset = TensorDataset(torch.FloatTensor(X_test_original), torch.FloatTensor((~mask_test).astype(float)))\n",
        "test2_dataset = TensorDataset(torch.FloatTensor(X_test2), torch.FloatTensor((~mask_test2).astype(float)))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "test2_loader = DataLoader(test2_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Preview a batch\n",
        "sample_batch_data, sample_batch_mask = next(iter(train_loader))\n",
        "print(f\"\\nSample batch shape: {sample_batch_data.shape}\")\n",
        "print(f\"Sample batch mask shape: {sample_batch_mask.shape}\")\n",
        "print(f\"Sample batch missing percentage: {(sample_batch_mask == 0).float().mean().item()*100:.1f}%\")  # 0 = missing in model tensors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6db75eb",
      "metadata": {},
      "source": [
        "## Simple Diffusion Imputation Model with Transformers\n",
        "\n",
        "This section implements a simple diffusion model for missing value imputation using:\n",
        "- **Transformers architecture** for the noise prediction network\n",
        "- **Diffusers library** for the diffusion scheduler and process\n",
        "- **Conditional generation** on observed values (mask)\n",
        "\n",
        "The model learns to denoise incomplete feature vectors, generating diverse completions for missing values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e68786",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install diffusers if not already installed\n",
        "try:\n",
        "    import diffusers\n",
        "    print(\"✓ diffusers library already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing diffusers library...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call([\"pip\", \"install\", \"diffusers\", \"transformers\"])\n",
        "    import diffusers\n",
        "    print(\"✓ diffusers library installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "003087d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import additional libraries for diffusion model\n",
        "from diffusers import DDPMScheduler\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f402934c",
      "metadata": {},
      "source": [
        "### Simple Transformer-based Noise Prediction Model\n",
        "\n",
        "We'll use a simple transformer encoder to predict the noise that needs to be removed at each diffusion step. The model takes:\n",
        "- **Noisy data**: The current noisy version of the feature vector\n",
        "- **Time step**: The current diffusion timestep\n",
        "- **Mask**: Which values are observed (conditioning information)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad384b5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleTransformerDiffusion(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple transformer-based diffusion model for imputation.\n",
        "    \n",
        "    Architecture:\n",
        "    - Transformer encoder for processing feature sequences\n",
        "    - Time embedding for diffusion timesteps\n",
        "    - Mask conditioning for observed values\n",
        "    - Output layer for noise prediction\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_dim=37, hidden_dim=128, num_layers=4, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # Time embedding (sinusoidal)\n",
        "        self.time_embed_dim = hidden_dim\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        \n",
        "        # Input projection: feature + mask + time_embed -> hidden_dim\n",
        "        self.input_proj = nn.Linear(input_dim * 2 + hidden_dim, hidden_dim)\n",
        "        \n",
        "        # Transformer encoder layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_dim * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        # Output projection: hidden_dim -> input_dim (noise prediction)\n",
        "        self.output_proj = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "        \n",
        "    def get_time_embedding(self, timesteps):\n",
        "        \"\"\"Create sinusoidal time embeddings.\"\"\"\n",
        "        half_dim = self.time_embed_dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=timesteps.device) * -emb)\n",
        "        emb = timesteps[:, None] * emb[None, :]\n",
        "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
        "        if self.time_embed_dim % 2 == 1:  # zero pad\n",
        "            emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n",
        "        return emb\n",
        "    \n",
        "    def forward(self, x_noisy, timesteps, mask):\n",
        "        \"\"\"\n",
        "        Predict noise to remove from noisy input.\n",
        "        \n",
        "        Args:\n",
        "            x_noisy: Noisy feature vectors [batch_size, input_dim]\n",
        "            timesteps: Diffusion timesteps [batch_size]\n",
        "            mask: Observed value mask [batch_size, input_dim] (1=observed, 0=missing)\n",
        "        \n",
        "        Returns:\n",
        "            noise_pred: Predicted noise [batch_size, input_dim]\n",
        "        \"\"\"\n",
        "        batch_size = x_noisy.shape[0]\n",
        "        \n",
        "        # Get time embeddings\n",
        "        time_emb = self.get_time_embedding(timesteps)\n",
        "        time_emb = self.time_mlp(time_emb)  # [batch_size, hidden_dim]\n",
        "        \n",
        "        # Prepare input: concatenate noisy data, mask, and time embedding\n",
        "        # Expand time embedding to match sequence length\n",
        "        time_emb_expanded = time_emb.unsqueeze(1).expand(-1, self.input_dim, -1)  # [batch, seq_len, hidden]\n",
        "        \n",
        "        # Prepare feature sequence: treat each feature as a token\n",
        "        x_expanded = x_noisy.unsqueeze(-1)  # [batch, input_dim, 1]\n",
        "        mask_expanded = mask.unsqueeze(-1)  # [batch, input_dim, 1]\n",
        "        \n",
        "        # Concatenate: [feature_value, mask_value, time_emb]\n",
        "        input_seq = torch.cat([x_expanded, mask_expanded, time_emb_expanded], dim=-1)  # [batch, input_dim, 2+hidden]\n",
        "        \n",
        "        # Project to hidden dimension\n",
        "        input_seq = self.input_proj(input_seq)  # [batch, input_dim, hidden_dim]\n",
        "        \n",
        "        # Pass through transformer\n",
        "        output = self.transformer(input_seq)  # [batch, input_dim, hidden_dim]\n",
        "        \n",
        "        # Pool and predict noise (mean pooling across sequence)\n",
        "        pooled = output.mean(dim=1)  # [batch, hidden_dim]\n",
        "        \n",
        "        # Predict noise\n",
        "        noise_pred = self.output_proj(pooled)  # [batch, input_dim]\n",
        "        \n",
        "        return noise_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c5d4025",
      "metadata": {},
      "source": [
        "### Training Setup for Diffusion Model\n",
        "\n",
        "The training process:\n",
        "1. Sample random timesteps\n",
        "2. Add noise to the data at those timesteps\n",
        "3. Predict the noise using the model\n",
        "4. Compute loss between predicted and actual noise\n",
        "5. Only compute loss on missing values (where mask=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e7a8a45",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize diffusion model\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DIFFUSION MODEL INITIALIZATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Model configuration\n",
        "diffusion_config = {\n",
        "    'input_dim': len(feature_names),\n",
        "    'hidden_dim': 128,\n",
        "    'num_layers': 4,\n",
        "    'num_heads': 4,\n",
        "    'dropout': 0.1,\n",
        "    'num_train_timesteps': 1000,  # Number of diffusion steps\n",
        "    'beta_schedule': 'linear',  # Noise schedule\n",
        "    'learning_rate': 1e-4,\n",
        "    'num_epochs': 100,\n",
        "    'patience': 20\n",
        "}\n",
        "\n",
        "print(f\"Diffusion Model Configuration:\")\n",
        "for key, value in diffusion_config.items():\n",
        "    print(f\"  - {key}: {value}\")\n",
        "\n",
        "# Initialize the noise prediction model\n",
        "diffusion_model = SimpleTransformerDiffusion(\n",
        "    input_dim=diffusion_config['input_dim'],\n",
        "    hidden_dim=diffusion_config['hidden_dim'],\n",
        "    num_layers=diffusion_config['num_layers'],\n",
        "    num_heads=diffusion_config['num_heads'],\n",
        "    dropout=diffusion_config['dropout']\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in diffusion_model.parameters() if p.requires_grad)\n",
        "print(f\"\\n✓ Diffusion model initialized with {total_params:,} parameters\")\n",
        "\n",
        "# Initialize diffusion scheduler\n",
        "noise_scheduler = DDPMScheduler(\n",
        "    num_train_timesteps=diffusion_config['num_train_timesteps'],\n",
        "    beta_schedule=diffusion_config['beta_schedule']\n",
        ")\n",
        "print(f\"✓ Noise scheduler initialized ({diffusion_config['num_train_timesteps']} timesteps)\")\n",
        "\n",
        "# Initialize optimizer\n",
        "diffusion_optimizer = optim.AdamW(\n",
        "    diffusion_model.parameters(),\n",
        "    lr=diffusion_config['learning_rate'],\n",
        "    weight_decay=1e-5\n",
        ")\n",
        "\n",
        "diffusion_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "    diffusion_optimizer, T_max=diffusion_config['num_epochs'], eta_min=1e-6\n",
        ")\n",
        "\n",
        "print(f\"✓ Optimizer initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830d4fc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training function for diffusion model\n",
        "def train_diffusion_step(model, scheduler, x, mask, optimizer):\n",
        "    \"\"\"\n",
        "    Single training step for diffusion model.\n",
        "    \n",
        "    Args:\n",
        "        model: Noise prediction model\n",
        "        scheduler: Diffusion noise scheduler\n",
        "        x: Clean data [batch, features]\n",
        "        mask: Observed value mask [batch, features] (1=observed, 0=missing)\n",
        "        optimizer: Optimizer\n",
        "    \n",
        "    Returns:\n",
        "        loss: Training loss\n",
        "    \"\"\"\n",
        "    # Sample random timesteps\n",
        "    timesteps = torch.randint(\n",
        "        0, scheduler.config.num_train_timesteps, (x.shape[0],), device=x.device\n",
        "    ).long()\n",
        "    \n",
        "    # Sample noise (only for missing values)\n",
        "    noise = torch.randn_like(x)\n",
        "    # Only add noise to missing positions\n",
        "    mask_float = mask.float()\n",
        "    noise = noise * (1 - mask_float)  # Zero noise for observed values\n",
        "    \n",
        "    # Add noise to data\n",
        "    noisy_samples = scheduler.add_noise(x, noise, timesteps)\n",
        "    \n",
        "    # Predict noise\n",
        "    noise_pred = model(noisy_samples, timesteps, mask)\n",
        "    \n",
        "    # Compute loss only on missing values\n",
        "    # Only compute loss where mask=0 (missing values)\n",
        "    missing_mask = (1 - mask_float)\n",
        "    loss = F.mse_loss(noise_pred * missing_mask, noise * missing_mask, reduction='sum')\n",
        "    loss = loss / (missing_mask.sum() + 1e-8)  # Normalize by number of missing values\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3be87ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop for diffusion model\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DIFFUSION MODEL TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "train_losses_diff = []\n",
        "val_losses_diff = []\n",
        "best_val_loss_diff = float('inf')\n",
        "patience_counter_diff = 0\n",
        "\n",
        "print(f\"Starting training for {diffusion_config['num_epochs']} epochs...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for epoch in range(diffusion_config['num_epochs']):\n",
        "    # Training phase\n",
        "    diffusion_model.train()\n",
        "    epoch_train_loss = 0\n",
        "    \n",
        "    train_progress = tqdm(train_loader, desc=f'Epoch {epoch+1}/{diffusion_config[\"num_epochs\"]}', leave=False)\n",
        "    \n",
        "    for batch_data, batch_mask in train_progress:\n",
        "        batch_data = batch_data.to(device)\n",
        "        batch_mask = batch_mask.to(device)\n",
        "        \n",
        "        loss = train_diffusion_step(\n",
        "            diffusion_model, noise_scheduler, batch_data, batch_mask, diffusion_optimizer\n",
        "        )\n",
        "        \n",
        "        epoch_train_loss += loss\n",
        "        train_progress.set_postfix({'Loss': f'{loss:.4f}'})\n",
        "    \n",
        "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "    train_losses_diff.append(avg_train_loss)\n",
        "    \n",
        "    # Validation phase\n",
        "    diffusion_model.eval()\n",
        "    epoch_val_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_mask in val_loader:\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_mask = batch_mask.to(device)\n",
        "            \n",
        "            # Sample timesteps\n",
        "            timesteps = torch.randint(\n",
        "                0, noise_scheduler.config.num_train_timesteps, \n",
        "                (batch_data.shape[0],), device=device\n",
        "            ).long()\n",
        "            \n",
        "            # Sample noise\n",
        "            noise = torch.randn_like(batch_data)\n",
        "            mask_float = batch_mask.float()\n",
        "            noise = noise * (1 - mask_float)\n",
        "            \n",
        "            # Add noise\n",
        "            noisy_samples = noise_scheduler.add_noise(batch_data, noise, timesteps)\n",
        "            \n",
        "            # Predict noise\n",
        "            noise_pred = diffusion_model(noisy_samples, timesteps, batch_mask)\n",
        "            \n",
        "            # Compute loss\n",
        "            missing_mask = (1 - mask_float)\n",
        "            loss = F.mse_loss(noise_pred * missing_mask, noise * missing_mask, reduction='sum')\n",
        "            loss = loss / (missing_mask.sum() + 1e-8)\n",
        "            \n",
        "            epoch_val_loss += loss.item()\n",
        "    \n",
        "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
        "    val_losses_diff.append(avg_val_loss)\n",
        "    \n",
        "    # Learning rate scheduling\n",
        "    diffusion_scheduler.step()\n",
        "    \n",
        "    # Early stopping\n",
        "    if avg_val_loss < best_val_loss_diff:\n",
        "        best_val_loss_diff = avg_val_loss\n",
        "        patience_counter_diff = 0\n",
        "        torch.save(diffusion_model.state_dict(), 'diffusion_imputer.pth')\n",
        "    else:\n",
        "        patience_counter_diff += 1\n",
        "    \n",
        "    # Print progress\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{diffusion_config[\"num_epochs\"]}:')\n",
        "        print(f'  Train Loss: {avg_train_loss:.4f}')\n",
        "        print(f'  Val Loss: {avg_val_loss:.4f}, Best: {best_val_loss_diff:.4f}')\n",
        "        print(f'  LR: {diffusion_optimizer.param_groups[0][\"lr\"]:.2e}')\n",
        "        print(f'  Patience: {patience_counter_diff}/{diffusion_config[\"patience\"]}')\n",
        "    \n",
        "    # Early stopping\n",
        "    if patience_counter_diff >= diffusion_config['patience']:\n",
        "        print(f'\\nEarly stopping at epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "print(f'\\n✓ Training completed!')\n",
        "print(f'  - Total epochs: {len(train_losses_diff)}')\n",
        "print(f'  - Best validation loss: {best_val_loss_diff:.4f}')\n",
        "print(f'  - Final training loss: {train_losses_diff[-1]:.4f}')\n",
        "\n",
        "# Load best model\n",
        "diffusion_model.load_state_dict(torch.load('diffusion_imputer.pth'))\n",
        "print(f'✓ Best model loaded')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4010cb8a",
      "metadata": {},
      "source": [
        "### Sampling from the Diffusion Model\n",
        "\n",
        "To generate imputations, we start with pure noise and iteratively denoise it, while keeping observed values fixed at each step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70c281d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_diffusion(model, scheduler, x_incomplete, mask, num_inference_steps=50):\n",
        "    \"\"\"\n",
        "    Generate imputation using diffusion sampling.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained noise prediction model\n",
        "        scheduler: Diffusion scheduler\n",
        "        x_incomplete: Incomplete data with missing values [batch, features]\n",
        "        mask: Observed value mask [batch, features] (1=observed, 0=missing)\n",
        "        num_inference_steps: Number of denoising steps\n",
        "    \n",
        "    Returns:\n",
        "        imputed: Complete imputed data [batch, features]\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Set scheduler to inference mode\n",
        "    scheduler.set_timesteps(num_inference_steps)\n",
        "    \n",
        "    # Start with random noise for missing values, observed values from input\n",
        "    mask_float = mask.float()\n",
        "    x_t = torch.randn_like(x_incomplete)\n",
        "    # Set observed values immediately\n",
        "    x_t = x_t * (1 - mask_float) + x_incomplete * mask_float\n",
        "    \n",
        "    # Denoising loop\n",
        "    with torch.no_grad():\n",
        "        for t in scheduler.timesteps:\n",
        "            # Predict noise\n",
        "            noise_pred = model(x_t, t.expand(x_t.shape[0]), mask)\n",
        "            \n",
        "            # Denoise step\n",
        "            x_t = scheduler.step(noise_pred, t, x_t).prev_sample\n",
        "            \n",
        "            # Keep observed values fixed\n",
        "            x_t = x_t * (1 - mask_float) + x_incomplete * mask_float\n",
        "    \n",
        "    return x_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8930143",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation function for diffusion model\n",
        "def evaluate_diffusion_imputation(model, scheduler, data_loader, device, num_inference_steps=50):\n",
        "    \"\"\"Evaluate diffusion model imputation performance.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    all_imputations = []\n",
        "    all_originals = []\n",
        "    all_masks = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_mask in tqdm(data_loader, desc=\"Evaluating\"):\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_mask = batch_mask.to(device)\n",
        "            \n",
        "            # Generate imputation\n",
        "            imputed = sample_diffusion(\n",
        "                model, scheduler, batch_data, batch_mask, num_inference_steps\n",
        "            )\n",
        "            \n",
        "            # Combine observed values with imputed values\n",
        "            mask_float = batch_mask.float()\n",
        "            final_imputed = batch_data * mask_float + imputed * (1 - mask_float)\n",
        "            \n",
        "            all_imputations.append(final_imputed.cpu().numpy())\n",
        "            all_originals.append(batch_data.cpu().numpy())\n",
        "            all_masks.append(batch_mask.cpu().numpy())\n",
        "    \n",
        "    # Concatenate all results\n",
        "    imputations = np.vstack(all_imputations)\n",
        "    originals = np.vstack(all_originals)\n",
        "    masks = np.vstack(all_masks)\n",
        "    \n",
        "    return imputations, originals, masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd398bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DIFFUSION MODEL EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"Evaluating diffusion model on test set...\")\n",
        "test_imputations_diff, test_originals_diff, test_masks_diff = evaluate_diffusion_imputation(\n",
        "    diffusion_model, noise_scheduler, test_loader, device, num_inference_steps=50\n",
        ")\n",
        "\n",
        "print(f\"✓ Test set evaluation completed\")\n",
        "print(f\"  - Test samples: {test_imputations_diff.shape[0]}\")\n",
        "print(f\"  - Features: {test_imputations_diff.shape[1]}\")\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"\\nCalculating metrics...\")\n",
        "missing_mask = (test_masks_diff == 0)\n",
        "\n",
        "feature_metrics_diff = {}\n",
        "for i, feature_name in enumerate(feature_names):\n",
        "    if missing_mask[:, i].sum() > 0:\n",
        "        imputed_missing = test_imputations_diff[missing_mask[:, i], i]\n",
        "        ground_truth_missing = test_originals_diff[missing_mask[:, i], i]\n",
        "        \n",
        "        mse = mean_squared_error(ground_truth_missing, imputed_missing)\n",
        "        mae = mean_absolute_error(ground_truth_missing, imputed_missing)\n",
        "        \n",
        "        try:\n",
        "            correlation = np.corrcoef(ground_truth_missing, imputed_missing)[0, 1]\n",
        "        except:\n",
        "            correlation = np.nan\n",
        "        \n",
        "        mean_diff, js_div = calculate_jsd_and_mean_diff(\n",
        "            imputed_missing, ground_truth_missing, feature_name\n",
        "        )\n",
        "        \n",
        "        feature_metrics_diff[feature_name] = {\n",
        "            'n_missing': missing_mask[:, i].sum(),\n",
        "            'mse': mse,\n",
        "            'mae': mae,\n",
        "            'correlation': correlation,\n",
        "            'mean_difference': mean_diff,\n",
        "            'js_divergence': js_div,\n",
        "        }\n",
        "\n",
        "print(f\"✓ Metrics calculated for {len(feature_metrics_diff)} features\")\n",
        "\n",
        "# Display summary\n",
        "all_mse = [m['mse'] for m in feature_metrics_diff.values()]\n",
        "all_mae = [m['mae'] for m in feature_metrics_diff.values()]\n",
        "all_corr = [m['correlation'] for m in feature_metrics_diff.values() if not np.isnan(m['correlation'])]\n",
        "\n",
        "print(f\"\\nSummary Statistics:\")\n",
        "print(f\"  - Average MSE: {np.mean(all_mse):.4f} ± {np.std(all_mse):.4f}\")\n",
        "print(f\"  - Average MAE: {np.mean(all_mae):.4f} ± {np.std(all_mae):.4f}\")\n",
        "print(f\"  - Average Correlation: {np.mean(all_corr):.3f} ± {np.std(all_corr):.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4953b6ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate multiple samples for test set\n",
        "def generate_diffusion_samples(model, scheduler, X_test, test_loader, device, \n",
        "                                n_samples_per_test=100, num_inference_steps=50):\n",
        "    \"\"\"Generate multiple diverse samples using diffusion model.\"\"\"\n",
        "    test_samples = np.zeros((X_test.shape[0], n_samples_per_test, X_test.shape[1]))\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (batch_data, batch_mask) in enumerate(\n",
        "            tqdm(test_loader, desc=\"Generating Diffusion Samples\")\n",
        "        ):\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_mask = batch_mask.to(device)\n",
        "            \n",
        "            start_idx = batch_idx * test_loader.batch_size\n",
        "            end_idx = min(start_idx + test_loader.batch_size, X_test.shape[0])\n",
        "            actual_batch_size = end_idx - start_idx\n",
        "            \n",
        "            # Generate multiple samples for each item in batch\n",
        "            for j in range(n_samples_per_test):\n",
        "                imputed = sample_diffusion(\n",
        "                    model, scheduler, batch_data, batch_mask, num_inference_steps\n",
        "                )\n",
        "                \n",
        "                # Apply mask\n",
        "                mask_float = batch_mask.float()\n",
        "                final_imputed = batch_data * mask_float + imputed * (1 - mask_float)\n",
        "                \n",
        "                test_samples[start_idx:end_idx, j, :] = final_imputed.cpu().numpy()\n",
        "    \n",
        "    print(f\"✓ Generated samples shape: {test_samples.shape}\")\n",
        "    return test_samples\n",
        "\n",
        "# Generate samples for test2\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING TEST2 SAMPLES WITH DIFFUSION MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"Generating {100} samples for each of {X_test2.shape[0]} test2 samples...\")\n",
        "\n",
        "test2_samples_diff = generate_diffusion_samples(\n",
        "    diffusion_model, noise_scheduler, X_test2, test2_loader, device,\n",
        "    n_samples_per_test=100, num_inference_steps=50\n",
        ")\n",
        "\n",
        "# Save submission\n",
        "id_diff = np.random.randint(1e8, 1e9-1)\n",
        "np.save(f\"{id_diff}.npy\", test2_samples_diff)\n",
        "print(f\"✓ Saved submission file: {id_diff}.npy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0171f6fc",
      "metadata": {
        "id": "0171f6fc"
      },
      "source": [
        "### Data Preprocessing and Missing Value Handling\n",
        "\n",
        "This is a critical section where we prepare our data for the VAE model. Key points:\n",
        "\n",
        "**Missing Value Conventions:**\n",
        "- In CSV files: `-1` indicates missing values\n",
        "- In mask files: `True` = missing, `False` = observed\n",
        "- For PyTorch models: We convert to `1` = observed, `0` = missing (standard convention)\n",
        "\n",
        "**Why This Matters:**\n",
        "Our VAE needs to distinguish between observed values (which provide constraints) and missing values (which need to be generated). The mask tells the model which values to trust and which to predict."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d40a16",
      "metadata": {
        "id": "75d40a16"
      },
      "source": [
        "## VAE Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e859639",
      "metadata": {
        "id": "7e859639"
      },
      "outputs": [],
      "source": [
        "# VAE Model Architecture for Missing Value Imputation\n",
        "class VAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Variational Autoencoder designed for missing value imputation.\n",
        "\n",
        "    Key features:\n",
        "    - Handles arbitrary missing patterns through masking\n",
        "    - Learns feature dependencies in latent space\n",
        "    - Generates probabilistic imputations\n",
        "    - Uses residual connections and dropout for robustness\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, latent_dim=64, hidden_dims=[256, 128, 64],\n",
        "                 use_residual=True, dropout_rate=0.3):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.use_residual = use_residual\n",
        "        self.hidden_dims = hidden_dims\n",
        "\n",
        "        # Feature importance network (learns which features are important for each position)\n",
        "        self.feature_importance = nn.Sequential(\n",
        "            nn.Linear(input_dim * 2, hidden_dims[0] // 2),  # input + mask\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0] // 2, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Encoder with residual connections\n",
        "        self.encoder_layers = nn.ModuleList()\n",
        "        prev_dim = input_dim * 2  # input + mask\n",
        "\n",
        "        for i, hidden_dim in enumerate(hidden_dims):\n",
        "            self.encoder_layers.append(nn.Sequential(\n",
        "                nn.Linear(prev_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ))\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        # Latent space\n",
        "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)\n",
        "\n",
        "        # Initialize latent layers with smaller weights for stability\n",
        "        nn.init.xavier_normal_(self.fc_mu.weight, gain=0.1)\n",
        "        nn.init.xavier_normal_(self.fc_logvar.weight, gain=0.1)\n",
        "        nn.init.constant_(self.fc_logvar.bias, -2.0)  # Start with low variance\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        self.decoder_layers = nn.ModuleList()\n",
        "        prev_dim = latent_dim + input_dim + input_dim  # latent + observed + positional encoding\n",
        "\n",
        "        reversed_dims = list(reversed(hidden_dims))\n",
        "        for i, hidden_dim in enumerate(reversed_dims):\n",
        "            self.decoder_layers.append(nn.Sequential(\n",
        "                nn.Linear(prev_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ))\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        # Final output layer\n",
        "        self.output_layer = nn.Linear(hidden_dims[0], input_dim)\n",
        "        nn.init.xavier_normal_(self.output_layer.weight, gain=0.1)\n",
        "\n",
        "    def encode(self, x, mask):\n",
        "        \"\"\"Encode input with missing value masking.\"\"\"\n",
        "        # Calculate feature importance weights\n",
        "        mask_float = mask.float()\n",
        "        encoder_input = torch.cat([x * mask_float, mask_float], dim=1)\n",
        "        importance_weights = self.feature_importance(encoder_input)\n",
        "\n",
        "        # Apply importance weighting to the input\n",
        "        weighted_input = x * mask_float * importance_weights\n",
        "        encoder_input = torch.cat([weighted_input, mask_float], dim=1)\n",
        "\n",
        "        # Pass through encoder layers with residual connections\n",
        "        h = encoder_input\n",
        "        skip_connections = []\n",
        "\n",
        "        for i, layer in enumerate(self.encoder_layers):\n",
        "            prev_h = h\n",
        "            h = layer(h)\n",
        "\n",
        "            # Add residual connection for deeper layers\n",
        "            if self.use_residual and i > 0 and h.shape == prev_h.shape:\n",
        "                h = h + prev_h\n",
        "\n",
        "            skip_connections.append(h)\n",
        "\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "\n",
        "        # Clamp logvar to prevent numerical instability\n",
        "        logvar = torch.clamp(logvar, min=-10, max=10)\n",
        "\n",
        "        return mu, logvar, skip_connections\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"Reparameterization trick for VAE.\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, x_observed, mask):\n",
        "        \"\"\"Decode latent representation conditioned on observed values.\"\"\"\n",
        "        # Enhanced conditioning on observed values\n",
        "        mask_float = mask.float()\n",
        "        x_masked = x_observed * mask_float\n",
        "\n",
        "        # Add positional encoding for better feature understanding\n",
        "        pos_encoding = torch.arange(self.input_dim, dtype=torch.float32, device=z.device)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).expand(z.size(0), -1) / self.input_dim\n",
        "\n",
        "        # Concatenate latent code with observed values and positional encoding\n",
        "        decoder_input = torch.cat([z, x_masked, pos_encoding], dim=1)\n",
        "\n",
        "        # Pass through decoder layers\n",
        "        h = decoder_input\n",
        "        for layer in self.decoder_layers:\n",
        "            h = layer(h)\n",
        "\n",
        "        # Get reconstruction\n",
        "        reconstruction = self.output_layer(h)\n",
        "\n",
        "        return reconstruction\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"Forward pass through VAE.\"\"\"\n",
        "        mu, logvar, _ = self.encode(x, mask)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstruction = self.decode(z, x, mask)\n",
        "\n",
        "        return reconstruction, mu, logvar\n",
        "\n",
        "    def impute(self, x_incomplete, mask, n_samples=10):\n",
        "        \"\"\"Generate multiple imputation samples for missing values.\"\"\"\n",
        "        self.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Get multiple samples from the posterior\n",
        "            mu, logvar, _ = self.encode(x_incomplete, mask)\n",
        "\n",
        "            samples = []\n",
        "            for _ in range(n_samples):\n",
        "                z = self.reparameterize(mu, logvar)\n",
        "                reconstruction = self.decode(z, x_incomplete, mask)\n",
        "\n",
        "                # Combine observed values with imputed values\n",
        "                mask_float = mask.float()\n",
        "                imputed = x_incomplete * mask_float + reconstruction * (1 - mask_float)\n",
        "                samples.append(imputed.cpu().numpy())\n",
        "\n",
        "            samples = np.stack(samples, axis=1)  # Shape: (batch_size, n_samples, n_features)\n",
        "\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0835855",
      "metadata": {
        "id": "f0835855"
      },
      "outputs": [],
      "source": [
        "# Loss Functions and Training Utilities\n",
        "\n",
        "def vae_loss_function(recon_x, x, mu, logvar, mask, beta=1.0):\n",
        "    \"\"\"\n",
        "    Enhanced VAE loss function with missing value handling.\n",
        "\n",
        "    Args:\n",
        "        recon_x: Reconstructed data\n",
        "        x: Original data\n",
        "        mu: Mean of latent distribution\n",
        "        logvar: Log variance of latent distribution\n",
        "        mask: Binary mask (1 for observed, 0 for missing)\n",
        "        beta: Weight for KL divergence term\n",
        "    \"\"\"\n",
        "    # Reconstruction loss only on observed values\n",
        "    reconstruction_diff = (recon_x - x) ** 2\n",
        "\n",
        "    # Only consider observed values and normalize properly\n",
        "    masked_loss = reconstruction_diff * mask\n",
        "    recon_loss = masked_loss.sum() / (mask.sum() + 1e-8)\n",
        "\n",
        "    # Add standard MSE loss for stability\n",
        "    standard_recon_loss = F.mse_loss(recon_x * mask, x * mask, reduction='mean')\n",
        "    recon_loss = 0.7 * recon_loss + 0.3 * standard_recon_loss\n",
        "\n",
        "    # KL divergence with free bits to prevent posterior collapse\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    kl_loss = kl_loss / x.size(0)  # Normalize by batch size\n",
        "\n",
        "    total_loss = recon_loss + beta * kl_loss\n",
        "\n",
        "    return total_loss, recon_loss, kl_loss\n",
        "\n",
        "\n",
        "def get_beta_schedule(epoch, total_epochs, schedule_type='cosine'):\n",
        "    \"\"\"Get beta value for KL annealing schedule.\"\"\"\n",
        "    if schedule_type == 'linear':\n",
        "        return min(1.0, epoch / (total_epochs * 0.5))\n",
        "    elif schedule_type == 'sigmoid':\n",
        "        return 1.0 / (1.0 + np.exp(-(epoch - total_epochs * 0.5) / (total_epochs * 0.1)))\n",
        "    elif schedule_type == 'cosine':\n",
        "        return 0.5 * (1 + np.cos(np.pi * (1 - epoch / total_epochs)))\n",
        "    elif schedule_type == 'constant':\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 1.0\n",
        "\n",
        "\n",
        "def evaluate_imputation(model, data_loader, device):\n",
        "    \"\"\"Evaluate imputation performance.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_imputations = []\n",
        "    all_originals = []\n",
        "    all_masks = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_mask in data_loader:\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_mask = batch_mask.to(device)\n",
        "\n",
        "            # Get model predictions\n",
        "            reconstruction, mu, logvar = model(batch_data, batch_mask)\n",
        "\n",
        "            # Combine observed values with imputed values\n",
        "            mask_float = batch_mask.float()\n",
        "            imputed = batch_data * mask_float + reconstruction * (1 - mask_float)\n",
        "\n",
        "            all_imputations.append(imputed.cpu().numpy())\n",
        "            all_originals.append(batch_data.cpu().numpy())\n",
        "            all_masks.append(batch_mask.cpu().numpy())\n",
        "\n",
        "    # Concatenate all results\n",
        "    imputations = np.vstack(all_imputations)\n",
        "    originals = np.vstack(all_originals)\n",
        "    masks = np.vstack(all_masks)\n",
        "\n",
        "    return imputations, originals, masks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc20dea8",
      "metadata": {
        "id": "dc20dea8"
      },
      "source": [
        "### Loss Functions and Training Utilities\n",
        "\n",
        "The VAE loss function is crucial for training effectiveness. Our enhanced loss combines several components:\n",
        "\n",
        "**1. Reconstruction Loss**: Measures how well the model reconstructs observed values\n",
        "   - Only computed on observed values (respects the mask)\n",
        "\n",
        "**2. KL Divergence**: Regularizes the latent space to follow a standard normal distribution\n",
        "   - Prevents posterior collapse using \"free bits\"\n",
        "   - Controlled by β parameter for annealing\n",
        "\n",
        "**Beta Scheduling**: Gradually increases the KL weight during training to balance reconstruction and regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6214c61b",
      "metadata": {
        "id": "6214c61b"
      },
      "source": [
        "## Model Initialization and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e98e7b7",
      "metadata": {
        "id": "5e98e7b7"
      },
      "source": [
        "### Model Training Process\n",
        "\n",
        "This section implements the complete training pipeline with several important features:\n",
        "\n",
        "**Training Configuration:**\n",
        "- **Latent Dimension**: 128 (balance between expressiveness and computational efficiency)\n",
        "- **Architecture**: Deep encoder/decoder with residual connections\n",
        "- **Regularization**: Dropout and batch normalization for stability\n",
        "- **Optimization**: AdamW with cosine annealing for smooth convergence\n",
        "\n",
        "**Advanced Training Features:**\n",
        "- **Early Stopping**: Prevents overfitting by monitoring validation loss\n",
        "- **Gradient Clipping**: Ensures stable training by preventing exploding gradients  \n",
        "- **Beta Scheduling**: Gradual KL annealing for better latent space learning\n",
        "- **Learning Rate Scheduling**: Cosine annealing with warm restarts\n",
        "\n",
        "The training loop tracks multiple loss components to monitor model health and convergence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39e2a3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e39e2a3e",
        "outputId": "1cb0aef4-4565-4d6f-f061-29c39ff79ebd"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Model configuration\n",
        "config = {\n",
        "    'input_dim': len(feature_names),\n",
        "    'latent_dim': 128,\n",
        "    'hidden_dims': [512, 256, 128],\n",
        "    'use_residual': True,\n",
        "    'dropout_rate': 0.3,\n",
        "    'learning_rate': 1e-3,\n",
        "    'num_epochs': 500,\n",
        "    'beta_initial': 1.0,\n",
        "    'beta_schedule': 'cosine',\n",
        "    'patience': 15\n",
        "}\n",
        "\n",
        "print(f\"Model Configuration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  - {key}: {value}\")\n",
        "\n",
        "# Initialize the model\n",
        "print(f\"\\nInitializing VAE model...\")\n",
        "model = VAE(\n",
        "    input_dim=config['input_dim'],\n",
        "    latent_dim=config['latent_dim'],\n",
        "    hidden_dims=config['hidden_dims'],\n",
        "    use_residual=config['use_residual'],\n",
        "    dropout_rate=config['dropout_rate']\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"✓ Model initialized with {total_params:,} parameters\")\n",
        "\n",
        "# Initialize optimizer with improved settings\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config['learning_rate'],\n",
        "    weight_decay=1e-5,\n",
        "    betas=(0.9, 0.999),\n",
        "    eps=1e-8\n",
        ")\n",
        "\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=20, T_mult=2, eta_min=1e-6\n",
        ")\n",
        "\n",
        "print(f\"✓ Optimizer and scheduler initialized\")\n",
        "\n",
        "# Training setup\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_recon_losses = []\n",
        "train_kl_losses = []\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "print(f\"\\nStarting training for {config['num_epochs']} epochs...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(config['num_epochs']):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    epoch_train_loss = 0\n",
        "    epoch_recon_loss = 0\n",
        "    epoch_kl_loss = 0\n",
        "\n",
        "    # Get beta for this epoch\n",
        "    beta = get_beta_schedule(epoch, config['num_epochs'], config['beta_schedule'])\n",
        "\n",
        "    train_progress = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"num_epochs\"]}', leave=False)\n",
        "\n",
        "    for batch_data, batch_mask in train_progress:\n",
        "        batch_data = batch_data.to(device)\n",
        "        batch_mask = batch_mask.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        reconstruction, mu, logvar = model(batch_data, batch_mask)\n",
        "\n",
        "        # Calculate loss\n",
        "        total_loss, recon_loss, kl_loss = vae_loss_function(\n",
        "            reconstruction, batch_data, mu, logvar, batch_mask,\n",
        "            beta=beta\n",
        "        )\n",
        "\n",
        "        # Backward pass\n",
        "        total_loss.backward()\n",
        "\n",
        "        # Gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate losses\n",
        "        epoch_train_loss += total_loss.item()\n",
        "        epoch_recon_loss += recon_loss.item()\n",
        "        epoch_kl_loss += kl_loss.item()\n",
        "\n",
        "        # Update progress bar\n",
        "        train_progress.set_postfix({\n",
        "            'Loss': f'{total_loss.item():.4f}',\n",
        "            'Recon': f'{recon_loss.item():.4f}',\n",
        "            'KL': f'{kl_loss.item():.4f}',\n",
        "            'Beta': f'{beta:.3f}'\n",
        "        })\n",
        "\n",
        "    # Calculate average training losses\n",
        "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "    avg_recon_loss = epoch_recon_loss / len(train_loader)\n",
        "    avg_kl_loss = epoch_kl_loss / len(train_loader)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    epoch_val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_mask in val_loader:\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_mask = batch_mask.to(device)\n",
        "\n",
        "            reconstruction, mu, logvar = model(batch_data, batch_mask)\n",
        "\n",
        "            total_loss, _, _ = vae_loss_function(\n",
        "                reconstruction, batch_data, mu, logvar, batch_mask,\n",
        "                beta=beta\n",
        "            )\n",
        "\n",
        "            epoch_val_loss += total_loss.item()\n",
        "\n",
        "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
        "\n",
        "    # Store losses\n",
        "    train_losses.append(avg_train_loss)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    train_recon_losses.append(avg_recon_loss)\n",
        "    train_kl_losses.append(avg_kl_loss)\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step()\n",
        "\n",
        "    # Early stopping and model saving\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        # Save best model\n",
        "        torch.save(model.state_dict(), 'best_vae_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    # Print progress every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{config[\"num_epochs\"]}:')\n",
        "        print(f'  Train Loss: {avg_train_loss:.4f} (Recon: {avg_recon_loss:.4f}, KL: {avg_kl_loss:.4f})')\n",
        "        print(f'  Val Loss: {avg_val_loss:.4f}, Best: {best_val_loss:.4f}')\n",
        "        print(f'  Beta: {beta:.3f}, LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
        "        print(f'  Patience: {patience_counter}/{config[\"patience\"]}')\n",
        "\n",
        "    # Early stopping\n",
        "    if patience_counter >= config['patience']:\n",
        "        print(f'\\nEarly stopping at epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "print(f'\\n✓ Training completed!')\n",
        "print(f'  - Total epochs: {len(train_losses)}')\n",
        "print(f'  - Best validation loss: {best_val_loss:.4f}')\n",
        "print(f'  - Final training loss: {train_losses[-1]:.4f}')\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load('best_vae_model.pth'))\n",
        "print(f'✓ Best model loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abb9718e",
      "metadata": {
        "id": "abb9718e"
      },
      "source": [
        "## Model Evaluation and Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a04c0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11a04c0c",
        "outputId": "bc410595-ee1b-4b1e-85ff-30aacfe1353c"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"Evaluating model on test set...\")\n",
        "test_imputations, test_originals, test_masks = evaluate_imputation(\n",
        "    model, test_loader, device\n",
        ")\n",
        "\n",
        "print(f\"✓ Test set evaluation completed\")\n",
        "print(f\"  - Test samples: {test_imputations.shape[0]}\")\n",
        "print(f\"  - Features: {test_imputations.shape[1]}\")\n",
        "\n",
        "test_imputations_denorm = test_imputations  # Already in original scale\n",
        "test_original_denorm = X_test_original  # Already in original scale\n",
        "\n",
        "# Calculate comprehensive metrics\n",
        "print(\"\\nCalculating comprehensive metrics...\")\n",
        "feature_metrics = {}\n",
        "\n",
        "# Create masks for missing values (where we need to evaluate imputation)\n",
        "missing_mask = (test_masks == 0)  # True where values were missing (0 in model tensors = missing)\n",
        "\n",
        "for i, feature_name in enumerate(feature_names):\n",
        "    if missing_mask[:, i].sum() > 0:  # Only evaluate features with missing values\n",
        "        # Get imputed and ground truth values for missing positions only\n",
        "        imputed_missing = test_imputations_denorm[missing_mask[:, i], i]\n",
        "        ground_truth_missing = test_original_denorm[missing_mask[:, i], i]\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse = mean_squared_error(ground_truth_missing, imputed_missing)\n",
        "        mae = mean_absolute_error(ground_truth_missing, imputed_missing)\n",
        "\n",
        "        # Correlation\n",
        "        try:\n",
        "            correlation = np.corrcoef(ground_truth_missing, imputed_missing)[0, 1]\n",
        "        except:\n",
        "            correlation = np.nan\n",
        "\n",
        "        # Mean difference and Jensen-Shannon divergence\n",
        "        mean_diff, js_div = calculate_jsd_and_mean_diff(\n",
        "            imputed_missing, ground_truth_missing, feature_name\n",
        "        )\n",
        "\n",
        "        feature_metrics[feature_name] = {\n",
        "            'n_missing': missing_mask[:, i].sum(),\n",
        "            'mse': mse,\n",
        "            'mae': mae,\n",
        "            'correlation': correlation,\n",
        "            'mean_difference': mean_diff,\n",
        "            'js_divergence': js_div,\n",
        "        }\n",
        "\n",
        "print(f\"✓ Metrics calculated for {len(feature_metrics)} features with missing values\")\n",
        "\n",
        "# Display metrics for last 4 features (as requested)\n",
        "print(f\"\\n\" + \"=\"*100)\n",
        "print(\"METRICS FOR LAST 4 FEATURES\")\n",
        "print(\"=\"*100)\n",
        "print(f\"{'Feature':<15} {'N_Miss':<8} {'MSE':<10} {'MAE':<10} {'Corr':<8} {'Mean_Diff':<10} {'JS_Div':<8}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "last_4_features = list(feature_metrics.keys())[-4:] if len(feature_metrics) >= 4 else list(feature_metrics.keys())\n",
        "\n",
        "for feature in last_4_features:\n",
        "    metrics = feature_metrics[feature]\n",
        "    print(f\"{feature:<15} {metrics['n_missing']:<8} {metrics['mse']:<10.4f} {metrics['mae']:<10.4f} \"\n",
        "          f\"{metrics['correlation']:<8.3f} {metrics['mean_difference']:<10.4f} {metrics['js_divergence']:<8.4f} \")\n",
        "\n",
        "# Summary statistics\n",
        "all_mse = [m['mse'] for m in feature_metrics.values() if not np.isnan(m['mse'])]\n",
        "all_mae = [m['mae'] for m in feature_metrics.values() if not np.isnan(m['mae'])]\n",
        "all_corr = [m['correlation'] for m in feature_metrics.values() if not np.isnan(m['correlation'])]\n",
        "all_mean_diff = [m['mean_difference'] for m in feature_metrics.values() if not np.isnan(m['mean_difference'])]\n",
        "all_js_div = [m['js_divergence'] for m in feature_metrics.values() if not np.isnan(m['js_divergence'])]\n",
        "\n",
        "print(f\"\\nSummary Statistics Across All Features:\")\n",
        "print(f\"  - Average MSE: {np.mean(all_mse):.4f} ± {np.std(all_mse):.4f}\")\n",
        "print(f\"  - Average MAE: {np.mean(all_mae):.4f} ± {np.std(all_mae):.4f}\")\n",
        "print(f\"  - Average Correlation: {np.mean(all_corr):.3f} ± {np.std(all_corr):.3f}\")\n",
        "print(f\"  - Average Mean Difference: {np.mean(all_mean_diff):.4f} ± {np.std(all_mean_diff):.4f}\")\n",
        "print(f\"  - Average JS Divergence: {np.mean(all_js_div):.4f} ± {np.std(all_js_div):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43ff39cd",
      "metadata": {
        "id": "43ff39cd"
      },
      "source": [
        "### Model Evaluation and Comprehensive Metrics\n",
        "\n",
        "This section evaluates our trained VAE on the test set using multiple complementary metrics. Since we're dealing with missing value imputation, we only evaluate the model's predictions on positions that were originally missing.\n",
        "\n",
        "**Key Evaluation Metrics:**\n",
        "\n",
        "**1. Mean Squared Error (MSE)**:\n",
        "- Measures average squared difference between predicted and true values\n",
        "- Lower is better; sensitive to outliers\n",
        "- Good for understanding magnitude of errors\n",
        "\n",
        "**2. Correlation Coefficient**:\n",
        "- Measures linear relationship strength between predictions and dataset\n",
        "- Range: [-1, 1], closer to 1 is better\n",
        "- Shows if model captures feature relationships\n",
        "\n",
        "**3. Jensen-Shannon (JS) Divergence**:\n",
        "- Measures difference between predicted and true value distributions\n",
        "- Range: [0, 1], closer to 0 is better\n",
        "- Captures whether model preserves the overall data distribution\n",
        "\n",
        "**4. Maximum Mean Discrepancy (MMD)**:\n",
        "- Measures distributional difference using kernel methods (RBF kernel)\n",
        "- Range: [0, ∞], closer to 0 is better\n",
        "- Non-parametric test for comparing distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a047bb73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a047bb73",
        "outputId": "5cc6a8a5-9ade-4bb8-f7a1-d44721e9b688"
      },
      "outputs": [],
      "source": [
        "# Create the visualization\n",
        "plot_prediction_scatter(test_imputations_denorm, test_original_denorm, test_masks, feature_names, n_features=25)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IDgv-wkViD-u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "IDgv-wkViD-u",
        "outputId": "4eaea130-04a8-4ca0-b95a-0722caa11e89"
      },
      "outputs": [],
      "source": [
        "# Distribution comparison plots\n",
        "plot_distribution_comparison(test_imputations_denorm, test_original_denorm,\n",
        "                             test_masks, feature_names, n_features=25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4be0b2e3",
      "metadata": {
        "id": "4be0b2e3"
      },
      "source": [
        "### Distribution Comparison Visualizations\n",
        "\n",
        "Visual comparison of predicted vs. dataset distributions is crucial for understanding model performance beyond simple error metrics. These plots help us assess:\n",
        "\n",
        "**What the Plots Show:**\n",
        "- **Red (Imputed)**: Distribution of model's predicted values for missing positions\n",
        "- **Blue (Dataset)**: Distribution of actual values at those same positions\n",
        "- **Overlap**: How well the model captures the true data distribution\n",
        "\n",
        "**Why This Matters:**\n",
        "- A good generative model should not just minimize error, but also preserve the statistical properties of the data\n",
        "- If distributions match well, the model is generating realistic values\n",
        "- Large differences indicate the model may be systematically biased or missing important patterns\n",
        "\n",
        "**Interpretation:**\n",
        "- **Good**: Overlapping distributions with similar shapes and centers\n",
        "- **Concerning**: Shifted means, different variances, or completely different shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lI7StssOGmfp",
      "metadata": {
        "id": "lI7StssOGmfp"
      },
      "outputs": [],
      "source": [
        "def generate_samples(model, X_test, test_loader, device, n_samples_per_test=100):\n",
        "    \"\"\"Generate multiple samples for a dataset using the trained model.\n",
        "    \"\"\"\n",
        "    # We'll generate multiple samples\n",
        "    test_samples = np.zeros((X_test.shape[0], n_samples_per_test, X_test.shape[1]))\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Create a progress bar for all samples\n",
        "        from tqdm import tqdm\n",
        "\n",
        "        for batch_idx, (batch_data, batch_mask) in enumerate(tqdm(test_loader, desc=\"Generating Samples\")):\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_mask = batch_mask.to(device)\n",
        "\n",
        "            # Calculate the indices for this batch\n",
        "            start_idx = batch_idx * test_loader.batch_size\n",
        "            end_idx = min(start_idx + test_loader.batch_size, X_test.shape[0])\n",
        "            actual_batch_size = end_idx - start_idx\n",
        "\n",
        "            # Generate multiple samples for each item in the batch\n",
        "            for j in range(n_samples_per_test):\n",
        "                # Get reconstruction\n",
        "                reconstruction, mu, logvar = model(batch_data, batch_mask) # TODO: Change this line based on the model you use\n",
        "\n",
        "                # Apply mask: keep original values where available, use reconstructed values where missing\n",
        "                mask_float = batch_mask.float()\n",
        "                imputed = batch_data * mask_float + reconstruction * (1 - mask_float)\n",
        "\n",
        "                # Store the samples (already in original scale since we didn't normalize)\n",
        "                test_samples[start_idx:end_idx, j, :] = imputed.cpu().numpy()\n",
        "    print(f\"✓ Generated samples shape: {test_samples.shape}\")\n",
        "    print(f\"  - {test_samples.shape[0]} samples\")\n",
        "    print(f\"  - {test_samples.shape[1]} generated variations per sample\")\n",
        "    print(f\"  - {test_samples.shape[2]} features per sample\")\n",
        "\n",
        "    # Data is already in original scale (no denormalization needed)\n",
        "    test_samples_final = test_samples.copy()\n",
        "\n",
        "    # Calculate summary statistics\n",
        "    mean_across_samples = test_samples_final.mean(axis=1)  # Mean across the 100 samples\n",
        "\n",
        "    print(f\"  - Range of means: [{mean_across_samples.min():.4f}, {mean_across_samples.max():.4f}]\")\n",
        "\n",
        "    return test_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sjkbko3oFJQV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjkbko3oFJQV",
        "outputId": "f5224d48-f821-428d-f99a-d059b8150dbc"
      },
      "outputs": [],
      "source": [
        "# Test Evaluation\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TEST EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Generate multiple samples for test using the trained model\n",
        "print(f\"Generating 100 samples for each of {X_test.shape[0]} test samples...\")\n",
        "\n",
        "test_samples = generate_samples(\n",
        "    model, X_test, test_loader, device, n_samples_per_test=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JFWebQ2AzSsJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFWebQ2AzSsJ",
        "outputId": "4c12f4f3-dadf-4384-f101-32fb536fb139"
      },
      "outputs": [],
      "source": [
        "test_score = compute_score(generated_samples=test_samples, set_name='test')\n",
        "print(\"Test score:\", test_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zlA9iSSZcYlh",
      "metadata": {
        "id": "zlA9iSSZcYlh"
      },
      "source": [
        "The final score is computed as: Mean Correlation − Mean JS Divergence − Mean MSE\n",
        "\n",
        "Just as we compare generated samples for the test set against the original unimputed values, we will apply the same metric to the samples you generate for test2, using the hidden test2 set. This will determine your final submission score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7de3489",
      "metadata": {
        "id": "b7de3489"
      },
      "source": [
        "## Preparing a submission:\n",
        "Let's prepare a submission. We expect the final submission to be a 417x100x37 numpy array. These correspond to the 100 diverse samples you generated based on the constrained parameters we provided in the test2 set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6a8623",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d6a8623",
        "outputId": "fa7b08fc-4fee-472f-ea8c-f6ab635e3bc2"
      },
      "outputs": [],
      "source": [
        "# Test2 Evaluation\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TEST2 EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Generate multiple samples for test2 using the trained model\n",
        "print(f\"Generating 100 samples for each of {X_test2.shape[0]} test2 samples...\")\n",
        "\n",
        "test2_samples = generate_samples(\n",
        "    model, X_test2, test2_loader, device, n_samples_per_test=100\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bacf0675",
      "metadata": {
        "id": "bacf0675"
      },
      "source": [
        "### Test2 Evaluation: Generating Diverse Design Completions\n",
        "\n",
        "This is the core evaluation for your AI Copilot assignment. Here we:\n",
        "\n",
        "**Input**: Test2 samples with some known features (constraints) and some missing features (free parameters)\n",
        "\n",
        "**Output**: 100 diverse, plausible completions for each test sample\n",
        "\n",
        "**Why 100 Samples?**\n",
        "- Engineers want to explore multiple design options, not just one \"best\" solution\n",
        "- Diversity helps discover unexpected but valid design combinations  \n",
        "\n",
        "**Technical Process:**\n",
        "1. For each test2 sample, use the trained model to generate 100 different completions\n",
        "2. Each completion respects the known constraints (observed values)\n",
        "3. Missing values are filled with diverse, model-generated predictions\n",
        "4. Final output: 417 × 100 × 37 array (417 test samples, 100 variants each, 37 features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc755a46",
      "metadata": {
        "id": "fc755a46"
      },
      "outputs": [],
      "source": [
        "id = np.random.randint(1e8, 1e9-1)\n",
        "np.save(f\"{id}.npy\", test2_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2044ff7",
      "metadata": {
        "id": "d2044ff7"
      },
      "source": [
        "### Summary and Tips for CP3\n",
        "\n",
        "The VAE baseline reproduces the dataset distribution well for some features, but others still show substantial discrepancies, indicating significant room for improvement!\n",
        "\n",
        "**Key Observations:**\n",
        "- **Strengths**: The model captures general feature ranges and some distributional patterns\n",
        "- **Weaknesses**: Some features show systematic bias or poor distribution matching\n",
        "- **Opportunities**: Advanced architectures (diffusion models, transformers) or better conditioning strategies could improve performance\n",
        "\n",
        "**For Your Assignment**: Consider these results as a baseline. Think about:\n",
        "- Which features are hardest to predict and why?\n",
        "- How could you modify the architecture or training process?\n",
        "- What additional constraints or domain knowledge could help?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.13.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
